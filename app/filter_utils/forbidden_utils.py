# app/filter_utils/forbidden_utils.py

import hgtk
import time
import ahocorasick
from app.database import db_session
from db_models.forbidden import ForbiddenWord
from sqlalchemy.exc import IntegrityError
from datetime import datetime, timedelta
import app.state as state

from konlpy.tag import Mecab
# mecab = Mecab()
mecab = Mecab(dicpath="/opt/homebrew/Cellar/mecab-ko-dic/2.1.1-20180720/lib/mecab/dic/mecab-ko-dic")

exclude_for_jamo = set()

def decompose_text(text: str) -> str:
    return hgtk.text.decompose(text).replace('á´¥', '')

def prepare_forbidden_entry(word: str) -> dict:
    decomposed = decompose_text(word)
    return {"word": word, "decomposed_word": decomposed}

def prepare_forbidden_entries(words: list[str]) -> list[dict]:
    return [{"word": word, "decomposed_word": decompose_text(word)} for word in words]


def get_existing_words(words: list[str]) -> set[str]:
    """ê¸ˆì¹™ì–´ í…Œì´ë¸”ì—ì„œ ì´ë¯¸ ë“±ë¡ëœ ë‹¨ì–´ ì¡°íšŒ (ORM ë°©ì‹)"""
    if not words:
        return set()

    with db_session() as session:
        result = session.query(ForbiddenWord.word).filter(ForbiddenWord.word.in_(words)).all()
        return {
            str(row[0]).strip()
            for row in result
            if isinstance(row[0], str) and row[0].strip()
        }


def register_forbidden_word(word: str) -> dict:
    """ê¸ˆì¹™ì–´ ë“±ë¡ í•¨ìˆ˜ (ë‹¨ì¼) - ORM ë°©ì‹"""
    existing_words = get_existing_words([word])
    if word in existing_words:
        return {"created": False, "word": word}

    decomposed = decompose_text(word)

    with db_session() as session:
        # ORM ê°ì²´ ìƒì„± ë° ì¶”ê°€
        new_entry = ForbiddenWord(word=word, decomposed_word=decomposed)
        session.add(new_entry)

        # íŠ¸ë¼ì´ ë°˜ì˜
        add_to_automaton(word, decomposed)

        return {
            "created": True,
            "word": word,
            "decomposed_word": decomposed
        }
        

def insert_bulk_forbidden_words(words: list[str]) -> dict:
    """
    ì—¬ëŸ¬ ê¸ˆì¹™ì–´ë¥¼ DBì— ì¼ê´„ ë“±ë¡í•˜ê³  íŠ¸ë¼ì´ì— ë°˜ì˜ (ORM ë°©ì‹)
    - ì¤‘ë³µ ë‹¨ì–´ëŠ” ë“±ë¡í•˜ì§€ ì•Šê³  skippedë¡œ ì•ˆë‚´
    - ì—ëŸ¬ ë°œìƒí•œ ë‹¨ì–´ëŠ” failedë¡œ ê¸°ë¡
    """
    # 1. ì…ë ¥ ì •ë¦¬: ê³µë°± ì œê±° + ì¤‘ë³µ ì œê±° + ë¹ˆ ê°’ ì œê±°
    cleaned_words = list(set(w.strip() for w in words if w.strip()))

    if not cleaned_words:
        return {
            "registered": [],
            "skipped": [],
            "failed": [],
            "message": "âš ï¸ ë“±ë¡í•  ìœ íš¨í•œ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤."
        }

    # 2. ê¸°ì¡´ì— DBì— ë“±ë¡ëœ ë‹¨ì–´ ì¡°íšŒ
    existing_words = set(get_existing_words(cleaned_words))
    filtered_words = [w for w in cleaned_words if w not in existing_words]
    registered = []
    skipped = list(existing_words) 
    failed = []

    with db_session() as session:
        for word in filtered_words:
            try:
                decomposed = decompose_text(word)
                entry = ForbiddenWord(word=word, decomposed_word=decomposed)
                session.add(entry)
                session.flush()  # ì¤‘ë³µ ì—ëŸ¬ ì¡°ê¸° ê°ì§€

                add_to_automaton(word, decomposed)
                registered.append(word)

            except IntegrityError:
                print(f"âš ï¸ ì¤‘ë³µìœ¼ë¡œ ìŠ¤í‚µëœ ë‹¨ì–´: '{word}'")
                if isinstance(word, str) and word.strip():  # âœ… ìœ íš¨í•œ ë¬¸ìì—´ì¼ ë•Œë§Œ ì¶”ê°€
                    skipped.append(word)
                session.rollback()

            except Exception as e:
                print(f"âŒ '{word}' ë“±ë¡ ì‹¤íŒ¨: {e}")
                failed.append(word)
                session.rollback()
                
    # 4. skipped ì •ë¦¬
    skipped = [w for w in skipped if isinstance(w, str) and w.strip()]

    # 3. ì•ˆë‚´ ë©”ì‹œì§€ ì„¤ì •
    if registered and not failed:
        message = f"âœ… {len(registered)}ê°œ ë“±ë¡ ì™„ë£Œ, {len(skipped)}ê°œëŠ” ì´ë¯¸ ë“±ë¡ë¨"
    elif registered and failed:
        message = f"âš ï¸ {len(registered)}ê°œ ë“±ë¡, {len(skipped)}ê°œëŠ” ì´ë¯¸ ë“±ë¡, {len(failed)}ê°œ ì‹¤íŒ¨"
    elif not registered and skipped:
        message = f"â„¹ï¸ ëª¨ë‘ ì´ë¯¸ ë“±ë¡ëœ ë‹¨ì–´ì…ë‹ˆë‹¤ ({len(skipped)}ê°œ)"
    else:
        message = "âŒ ë“±ë¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

    return {
        "registered": registered,
        "skipped": skipped,
        "failed": failed,
        "message": message
    }


def load_automaton_from_db() -> ahocorasick.Automaton | None:
    """DBì—ì„œ ê¸ˆì¹™ì–´ ë¡œë”©í•˜ì—¬ íŠ¸ë¼ì´ ìƒì„± (ORM ë°©ì‹)"""
    automaton = ahocorasick.Automaton()
    inserted_words = set()
    unique_original_words = set()

    try:
        with db_session() as session:
            # âœ… ì„¸ì…˜ ë‚´ì—ì„œ í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œí•´ì„œ ë³µì‚¬í•´ë‘ 
            rows = session.query(ForbiddenWord.word, ForbiddenWord.decomposed_word).all()

        if not rows:
            print("âš ï¸ [ì£¼ì˜] ê¸ˆì¹™ì–´ê°€ DBì— ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return None

        for word, decomposed in rows:
            if word and word not in inserted_words:
                automaton.add_word(word, (word, "original"))
                inserted_words.add(word)
                unique_original_words.add(word)

            if decomposed and word not in exclude_for_jamo:
                jamo = decomposed.replace(" ", "")
                if len(jamo) >= 3 and jamo not in inserted_words:
                    automaton.add_word(jamo, (word, "decomposed"))
                    inserted_words.add(jamo)

        automaton.make_automaton()
        state.forbidden_automaton = automaton

        print(f"âœ… ì›í˜• {len(unique_original_words)}ê°œ, ìëª¨ {len(inserted_words - unique_original_words)}ê°œ ë“±ë¡ ì™„ë£Œ")

        return automaton

    except Exception as e:
        print(f"[âŒ ERROR] ê¸ˆì¹™ì–´ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None


def add_to_automaton(word: str, decomposed: str):
    """ê¸ˆì¹™ì–´ ë‹¨ì¼ ë“±ë¡ ì‹œ íŠ¸ë¼ì´ì— ë°˜ì˜"""
    if not state.forbidden_automaton:
        state.forbidden_automaton = ahocorasick.Automaton()
    
    if not state.forbidden_automaton.kind:
        state.forbidden_automaton.make_automaton()

    # ì›í˜• ë‹¨ì–´ ë“±ë¡
    if word not in state.forbidden_automaton:
        state.forbidden_automaton.add_word(word, (word, "original"))
        print(f"âœ… [ì¶”ê°€] '{word}' â†’ ì›í˜• ê¸ˆì¹™ì–´ ë“±ë¡ ì™„ë£Œ")
    else:
        print(f"âš ï¸ [ì¤‘ë³µ] '{word}' â†’ ì´ë¯¸ ì›í˜• ë“±ë¡ë¨")

    # ìëª¨ ë‹¨ì–´ ë“±ë¡
    jamo = decomposed.replace(" ", "")
    if word not in exclude_for_jamo and len(jamo) >= 3:
        if jamo == word:
            print(f"âš ï¸ [ìƒëµ] '{jamo}' â†’ ì›í˜•ê³¼ ìëª¨ê°€ ê°™ìŒ (ë“±ë¡ ìƒëµ)")
        elif jamo not in state.forbidden_automaton:
            state.forbidden_automaton.add_word(jamo, (word, "decomposed"))
            print(f"âœ… [ì¶”ê°€] '{jamo}' â†’ ìëª¨ ê¸ˆì¹™ì–´ ë“±ë¡ ì™„ë£Œ")
        else:
            print(f"âš ï¸ [ì¤‘ë³µ] '{jamo}' â†’ ì´ë¯¸ ìëª¨ ë“±ë¡ë¨")

    # ê¼­ ë‹¤ì‹œ ë¹Œë“œí•´ì•¼ í•¨ (ahocorasickëŠ” build ì´í›„ì—ë§Œ íƒìƒ‰ ê°€ëŠ¥)
    state.forbidden_automaton.make_automaton()

ALLOWED_POS_PREFIXES = ('N', 'V', 'M', 'VA', 'XR', 'IC')  # ëª…ì‚¬, ë™ì‚¬, ë¶€ì‚¬, í˜•ìš©ì‚¬, ì–´ê·¼, ê°íƒ„ì‚¬

def extract_meaningful_tokens(message: str) -> list[str]:
    tokens = mecab.pos(message)
    return [token for token, pos in tokens if not pos.startswith('J') and any(pos.startswith(prefix) for prefix in ALLOWED_POS_PREFIXES)]

def generate_ngrams(tokens: list[str], n_range=(2, 3)) -> set[str]:
    ngram_set = set()
    for n in range(n_range[0], n_range[1]+1):
        for i in range(len(tokens) - n + 1):
            ngram = ''.join(tokens[i:i+n])
            ngram_set.add(ngram)
    return ngram_set

def check_forbidden_message(message: str) -> dict:
    """ë©”ì‹œì§€ í•œ ê°œì— ëŒ€í•´ ê¸ˆì¹™ì–´ í¬í•¨ ì—¬ë¶€ ê²€ì‚¬ (í˜•íƒœì†Œ ê¸°ë°˜ ë‹¨ì–´ë§Œ ê²€ì‚¬)"""
    start_time = time.time()
    automaton = state.forbidden_automaton
    # decomposed = decompose_text(message)

    tokens = extract_meaningful_tokens(message)
    token_set = set(tokens)
    meaningful_tokens = token_set
    # meaningful_tokens = token_set | ngram_set  # ë‹¨ì–´ + ngram ë³‘í•©
    # print(f"âœ… í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼: {meaningful_tokens}")

    # 1ì°¨: ì›í˜• ê²€ì‚¬
    for _, (word, mode) in automaton.iter(message):
        if mode == "original" and word in meaningful_tokens:
            elapsed = time.time() - start_time
            return {
                "message": message,
                "result": "ğŸš« ê¸ˆì¹™ì–´ í¬í•¨",
                "detected_words": [word],
                "method": "ì›í˜•",
                "inference_time": round(elapsed, 4)
            }

    # 2ì°¨: ìëª¨ ê²€ì‚¬
    # for _, (word, mode) in automaton.iter(decomposed):
    for _, (word, mode) in automaton.iter(message):
        if mode == "decomposed" and word in meaningful_tokens:
            elapsed = time.time() - start_time
            return {
                "message": message,
                "result": "ğŸš« ê¸ˆì¹™ì–´ í¬í•¨",
                "detected_words": [word],
                "method": "ìëª¨",
                "inference_time": round(elapsed, 4)
            }

    # í†µê³¼
    elapsed = time.time() - start_time
    return {
        "message": message,
        "result": "âœ… í†µê³¼",
        "detected_words": [],
        "method": "-",
        "inference_time": round(elapsed, 4)
    }


def get_all_forbidden_words() -> list[dict]:
    """
    ê¸ˆì¹™ì–´ ì „ì²´ ì¡°íšŒ (ORM)
    """
    with db_session() as session:
        words = session.query(ForbiddenWord).all()
        return [
            {
                "word": word.word,
                "decomposed_word": word.decomposed_word,
                "created_at": word.created_at
            }
            for word in words
        ]
        
def is_forbidden_word(word: str) -> bool:
    """
    íŠ¹ì • ë‹¨ì–´ê°€ ê¸ˆì¹™ì–´ í…Œì´ë¸”ì— ì¡´ì¬í•˜ëŠ”ì§€ ì—¬ë¶€ ë°˜í™˜ (ORM)
    """
    with db_session() as session:
        exists = session.query(ForbiddenWord).filter(ForbiddenWord.word == word).first()
        return exists is not None
    
    
def delete_forbidden_word(word: str) -> bool:
    """
    íŠ¹ì • ê¸ˆì¹™ì–´ë¥¼ DBì—ì„œ ì‚­ì œ (ORM)
    """
    try:
        with db_session() as session:
            target = session.query(ForbiddenWord).filter(ForbiddenWord.word == word).first()
            if target:
                session.delete(target)
                session.commit()
                return True
            return False
    except Exception as e:
        print("âŒ ì‚­ì œ ì—ëŸ¬:", e)
        return False


def delete_forbidden_words_by_date(date_str: str) -> int:
    """
    íŠ¹ì • ë‚ ì§œì— ë“±ë¡ëœ ê¸ˆì¹™ì–´ë“¤ì„ DBì—ì„œ ì‚­ì œ
    :param date_str: YYYY-MM-DD í˜•ì‹ì˜ ë¬¸ìì—´
    :return: ì‚­ì œëœ ê¸ˆì¹™ì–´ ê°œìˆ˜
    """
    try:
        date = datetime.strptime(date_str, "%Y-%m-%d")
        next_date = date + timedelta(days=1)

        with db_session() as session:
            targets = session.query(ForbiddenWord).filter(
                ForbiddenWord.created_at >= date,
                ForbiddenWord.created_at < next_date
            ).all()

            deleted_count = len(targets)

            for word in targets:
                session.delete(word)
            session.commit()

            return deleted_count
    except Exception as e:
        print("âŒ ë‚ ì§œ ì‚­ì œ ì—ëŸ¬:", e)
        return -1  # ì—ëŸ¬ ì‹œ -1 ë°˜í™˜